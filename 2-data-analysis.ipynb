{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model training & Data Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bigml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8f7f8779e8b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mbigml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bigml'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import bigml.api\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Instantiate BigMl - need BigML's project id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "api = bigml.api.BigML(project='project/5db1644859f5c33b3c00076c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Sources files\n",
    "train_full_source = api.create_source('./full_train_edit.csv')\n",
    "test_source = api.create_source('./test_edit.csv')\n",
    "api.ok(test_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Datasets\n",
    "train_full_dataset = api.create_dataset(train_full_source)\n",
    "test_dataset = api.create_dataset(test_source)\n",
    "api.ok(train_full_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Splitting train_full in a train dataset and a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = api.create_dataset(\n",
    "    train_full_dataset, {\"name\": \"Train Dataset\",\n",
    "                         \"sample_rate\": 0.8, \"seed\": \"my seed\"})\n",
    "api.ok(train_dataset)\n",
    "test_dataset = api.create_dataset(\n",
    "    train_full_dataset, {\"name\": \"Validation Dataset\",\n",
    "                         \"sample_rate\": 0.8, \"seed\": \"my seed\",\n",
    "                         \"out_of_bag\": True})\n",
    "api.ok(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "ensemble = api.create_ensemble(\n",
    "    train_dataset, {\"objective_field\": \"SeriousDlqin2yrs\"})\n",
    "api.ok(ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching a prediction\n",
    "\n",
    "### making the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "prediction = api.create_batch_prediction(ensemble, test_dataset, {\n",
    "    \"name\": \"1st shot\",\n",
    "    \"all_fields\": True,\n",
    "    \"prediction_name\": \"Prediction\",\n",
    "    \"probabilities\": True\n",
    "})\n",
    "api.ok(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### downloading the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "api.download_batch_prediction(\n",
    "    'batchprediction/5dc036bc5299632024000e4f', filename=\"./prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILE TO LUNCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.read_csv(\"./prediction.csv\", index_col=0)\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the prediction's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Writing the confusion (FP, FN, TP, TN)\n",
    "\n",
    "\n",
    "def set_confusion(row):\n",
    "    if (row['SeriousDlqin2yrs'] == row['Prediction'] and row['SeriousDlqin2yrs'] == 0):\n",
    "        return 'TN'\n",
    "    if (row['SeriousDlqin2yrs'] == row['Prediction'] and row['SeriousDlqin2yrs'] == 1):\n",
    "        return 'TP'\n",
    "    if row['SeriousDlqin2yrs'] > row['Prediction']:\n",
    "        return 'FN'\n",
    "    return 'FP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "prediction_df['confusion'] = prediction_df.apply(set_confusion, axis=1)\n",
    "prediction_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting in csv the 100 biggest errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "prediction_df_classified = prediction_df.sort_values(\n",
    "    by=['confusion', '1 probability'], ascending=[True, True])\n",
    "confusion = prediction_df_classified.groupby(['confusion']).confusion.count()\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation du seuil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creation d'une colone d'erreur en fonction d'un seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def set_prediction_with_threshold(row, threshold):\n",
    "    if row['1 probability'] > threshold:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "prediction_df['my_prediction'] = prediction_df.apply(set_prediction_with_threshold, args=(0.5,), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def set_confusion(row):\n",
    "    if (row['SeriousDlqin2yrs'] == row['my_prediction'] and row['SeriousDlqin2yrs'] == 0):\n",
    "        return 'TN'\n",
    "    if (row['SeriousDlqin2yrs'] == row['my_prediction'] and row['SeriousDlqin2yrs'] == 1):\n",
    "        return 'TP'\n",
    "    if row['SeriousDlqin2yrs'] > row['my_prediction']:\n",
    "        return 'FN'\n",
    "    return 'FP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "prediction_df['confusion'] = prediction_df.apply(set_confusion, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def count_confusion_values(col):\n",
    "    try:\n",
    "        TN = col.value_counts().to_dict()['TN']\n",
    "    except:\n",
    "        TN = 0\n",
    "    try:\n",
    "        FN = col.value_counts().to_dict()['FN']\n",
    "    except:\n",
    "        FN = 0\n",
    "    try:\n",
    "        TP = col.value_counts().to_dict()['TP']\n",
    "    except:\n",
    "        TP = 0\n",
    "    try:\n",
    "        FP = col.value_counts().to_dict()['FP']\n",
    "    except:\n",
    "        FP = 0\n",
    "    return TN, FN, TP, FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix = count_confusion_values(prediction_df['confusion'])\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def profit_matrix(confusion_matrix):\n",
    "    TN_cost = 500\n",
    "    FN_cost = -2500\n",
    "    TP_cost = 0\n",
    "    FP_cost = -500\n",
    "    total_profit = (confusion_matrix[0] * TN_cost\n",
    "                  + confusion_matrix[1] * FN_cost\n",
    "                  + confusion_matrix[2] * TP_cost\n",
    "                  + confusion_matrix[3] * FP_cost)\n",
    "    return total_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "profit = profit_matrix(confusion_matrix)\n",
    "print(profit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing AUC\n",
    "\n",
    "En fonction du seuil:\n",
    "\n",
    "- courbe ROC => TPR / FPR\n",
    "    - TPR = TP / (TP + FN)\n",
    "    - FPR = FP / (FP + TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_tpr_fpr(confusion_matrix):\n",
    "    tpr = confusion_matrix[2] / (confusion_matrix[2] + confusion_matrix[1])\n",
    "    fpr = confusion_matrix[3] / (confusion_matrix[3] + confusion_matrix[0])\n",
    "    return [tpr, fpr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_with_threshold():\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    profit_list = []\n",
    "    threshold_list = []\n",
    "    \n",
    "    for i in range(101):\n",
    "        threshold = i/100\n",
    "        # set prediction threshold based\n",
    "        prediction_df['my_prediction'] = prediction_df.apply(\n",
    "            set_prediction_with_threshold,args=(threshold,), axis=1)\n",
    "        # creating the confusion column\n",
    "        prediction_df['confusion'] = prediction_df.apply(set_confusion, axis=1)\n",
    "        # creating the confusion matrix\n",
    "        confusion_matrix = count_confusion_values(prediction_df['confusion'])\n",
    "        # computing profit_list\n",
    "        profit = profit_matrix(confusion_matrix)\n",
    "        profit_list.append(profit)\n",
    "        # setting the fpr and tpr list\n",
    "        tpr_fpr_list = set_tpr_fpr(confusion_matrix)\n",
    "        tpr_list.append(tpr_fpr_list[0])\n",
    "        fpr_list.append(tpr_fpr_list[1])\n",
    "        # add threshold point\n",
    "        threshold_list.append(threshold)\n",
    "        \n",
    "    return tpr_list, fpr_list, profit_list, threshold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_list, fpr_list, profit_list, threshold_list = computing_with_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(threshold_list, profit_list)\n",
    "\n",
    "ymax = max(profit_list)\n",
    "xpos = profit_list.index(ymax)\n",
    "xmax = threshold_list[xpos]\n",
    "\n",
    "plt.axvline(x=xmax, color='r')\n",
    "plt.annotate(f\"{xmax}\", xy=(xmax, 0), xytext=(xmax + 0.05, 0))\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Profit')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best profit: {ymax} reached at threshold: {xmax}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr_list, tpr_list, color=\"orange\")\n",
    "# set options here\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.plot(fpr_list, fpr_list, color=\"navy\", linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC calculation\n",
    "\n",
    "- auc = P / (N +P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = prediction_df.loc[prediction_df[\"SeriousDlqin2yrs\"] == 1]\n",
    "negative = prediction_df.loc[prediction_df[\"SeriousDlqin2yrs\"] == 0]\n",
    "\n",
    "positive_over_negative = 0\n",
    "total_number = 0\n",
    "\n",
    "for positive_value in positive[\"1 probability\"]:\n",
    "    for negative_value in negative[\"1 probability\"]:\n",
    "        if positive_value > negative_value:\n",
    "            positive_over_negative += 1\n",
    "        total_number += 1\n",
    "\n",
    "auc = positive_over_negative / total_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"auc = {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning curves\n",
    "\n",
    "we need to know the performance of a model bites by bites (10%, 20%, ..., 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to split the train dataset and evaluate the model on each splitted set\n",
    "for i range(1,11):\n",
    "    train_split = api.create_dataset(\n",
    "        train_dataset, (\n",
    "            \"name\": f\"split {i}\"),\n",
    "            \"sample_rate\": i/10,\n",
    "            \"seed\": \"my seed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
